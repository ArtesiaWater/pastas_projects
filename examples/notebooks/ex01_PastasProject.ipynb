{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing timeseries and Pastas models with PastasProject<a id=\"top\"></a>\n",
    "\n",
    "This notebook shows how [Pastas](https://pastas.readthedocs.io/en/latest/) timeseries and models can be managed and stored on disk. Two storage systems are currently implemented:\n",
    "- [Arctic](https://arctic.readthedocs.io/en/latest/) is a timeseries/dataframe database that sits atop [MongoDB](https://www.mongodb.com). Arctic supports pandas.DataFrames.\n",
    "- [PyStore](https://github.com/ranaroussi/pystore) is a datastore (inspired by Arctic) created for storing pandas dataframes (especially timeseries) on disk. Data is stored using fastparquet and compressed with Snappy.\n",
    "\n",
    "## Content\n",
    "1. [Getting started](#1)\n",
    "2. [The Connector objects](#2)\n",
    "  1. [ArcticConnector](#2.1)\n",
    "  2. [PystoreConnector](#2.2)\n",
    "  3. [Database structure](#2.3)\n",
    "3. [Initializing a PastasProject](#3)\n",
    "4. [Managing timeseries](#4)\n",
    "  1. [Adding oseries and stresses](#4.1)\n",
    "  2. [Accessing timeseries and metadata](#4.2)\n",
    "  3. [Deleting oseries and stresses](#4.3)\n",
    "  4. [Overview of oseries and stresses](#4.4)\n",
    "5. [Managing Pastas models](#5)\n",
    "  1. [Creating a model](#5.1)\n",
    "  2. [Storing a model](#5.2)\n",
    "  3. [Loading a model](#5.3)\n",
    "  4. [Overview of models](#5.4)\n",
    "  5. [Deleting models](#5.5)\n",
    "6. [Bulk operations](#6)\n",
    "7. [Deleting database](#7)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## [1. Getting started](#top)<a id=\"1\"></a>\n",
    "\n",
    "Use the following steps to get your PC ready for this notebook if you haven't done so already:\n",
    "\n",
    "### Getting ready for Arctic\n",
    "1. Install [MongoDB community](https://www.mongodb.com/download-center/community).\n",
    "2. Install Arctic using pip: `pip install arctic`.\n",
    "3. Run MongoDB by typing `mongod --dbpath <your_path_here>` in your terminal, or if on Windows use the batch script `start_mongodb.bat`.\n",
    "\n",
    "### Getting ready for Pystore\n",
    "1. Install Snappy (see the [Pystore github](https://github.com/ranaroussi/pystore#dependencies) page for for instructions). For Windows users see [this page](https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-snappy)\n",
    "2. Install Pystore using pip: `pip install pystore`.\n",
    "\n",
    "\n",
    "If no errors were encountered, you're all set. \n",
    "\n",
    "<hr>\n",
    "\n",
    "## [2. The Connector objects](#top)<a id=\"2\"></a>\n",
    "This sections shows how to initialize a connection to a new database (connecting to an existing database works the same way).\n",
    "\n",
    "Import `pastas_projects` and some other modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbrak\\Anaconda3\\lib\\site-packages\\arctic\\store\\_pandas_ndarray_store.py:6: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import DataFrame, Series, Panel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pastas as ps\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, \"../..\")\n",
    "\n",
    "import pastas_projects as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.1 ArcticConnector](#top)<a id=\"2.1\"></a>\n",
    "\n",
    "Provide information about the database. The connection string tells Arctic where the database is running (by default, if running locally the address is `mongodb://localhost:<port number>`. The project name is the user specified name for the database. \n",
    "\n",
    "If the database already exists, Arctic will connect to that existing database. In this case we're using a new database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connstr = \"mongodb://localhost:27017/\"  # for docker container with name 'mongodb' running mongodb\n",
    "name = \"my_connector\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an ArcticConnector object. In this case the object initializes a new database and provides the connection to that database.\n",
    "\n",
    "_Note: You can ignore the warnings arctic throws at you about enabling sharding._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Library created, but couldn't enable sharding: no such command: 'enablesharding'. This is OK if you're not 'admin'\n",
      "Library created, but couldn't enable sharding: no such command: 'enablesharding'. This is OK if you're not 'admin'\n",
      "Library created, but couldn't enable sharding: no such command: 'enablesharding'. This is OK if you're not 'admin'\n"
     ]
    }
   ],
   "source": [
    "conn = pp.ArcticConnector(name, connstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at `conn`. This shows us how many oseries, stresses and models are contained in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ArcticConnector object> 'my_connector': 0 oseries, 0 stresses, 0 models"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the database is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.2 PystoreConnector](#top)<a id=\"2.2\"></a>\n",
    "\n",
    "The PystoreConnector requires the path to the directory containing the stores and a name for the connector. If the store already exists, pystore will link to that existing store. In this case we're creating a new store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./pystore\"\n",
    "name = \"my_second_connector\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the PystoreConnector object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn2 = pp.PystoreConnector(name, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at `conn2`. This shows us how many oseries, stresses and models are contained in the store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PystoreConnector object> 'my_second_connector': 0 oseries, 0 stresses, 0 models"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.3 Database structure](#top)<a id=\"2.3\"></a>\n",
    "\n",
    "Regardless of the type of Connector that is used, the database/store contains 3 libraries or collections. Each of these contains specific data related to the project. The three libraries are:\n",
    "- oseries\n",
    "- stresses\n",
    "- models\n",
    "\n",
    "These libraries can be accessed through `conn.get_library()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VersionStore at 0x21b2c4cdc18>\n",
       "    <ArcticLibrary at 0x21b2c2faa20, arctic_my_connector.oseries>\n",
       "        <Arctic at 0x21b28f470f0, connected to MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True, maxpoolsize=4, sockettimeoutms=600000, connecttimeoutms=2000, serverselectiontimeoutms=30000)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the ArcticConnector\n",
    "conn.get_library(\"oseries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyStore.collection <stresses>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the PystoreConnector\n",
    "conn2.get_library(\"stresses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library handles are not generally used directly but internally they manage the reading, writing and deleting of data from the database/store. The two handles to the libraries above are completely different objects from two different packages (arctic and pystore). To understand what they're capable of and how they work please refer to the documentation of their respective packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## [3. Initializing a `PastasProject` object](#top)<a id=\"3\"></a>\n",
    "\n",
    "The `PastasProject` object is used process and use the data in the database. The connector objects only manage the reading/writing/deleting of data. The `PastasProject` contains all kinds of methods to actually _do_ stuff with that data. \n",
    "\n",
    "In order to access the data the `PastasProject` object must be initialized with a Connector object. In this example, I'm using the `PystoreConnector`, but I could just as easily have used the `ArcticConnector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pp.PastasProject(\"my_first_project\", conn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PastasProject> my_first_project: \n",
       " - <PystoreConnector object> 'my_second_connector': 0 oseries, 0 stresses, 0 models"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important thing to remember about the `PastasProject` is that the connector is accessible through `pr.db`. So all of the methods defined in the connector objects can be accessed through e.g. `pr.db.get_library`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## [4. Managing timeseries](#top)<a id=\"4\"></a>\n",
    "\n",
    "This section explains how timeseries can be added, retrieved or deleted from the database. We'll be using the `PastasProject` object we created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.1 Adding oseries and stresses](#top)<a id=\"4.1\"></a>\n",
    "\n",
    "Let's read some data to put into the database as an oseries. The data we are using is in the `tests/data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1985-11-14</td>\n",
       "      <td>27.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1985-11-28</td>\n",
       "      <td>27.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1985-12-14</td>\n",
       "      <td>27.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1985-12-28</td>\n",
       "      <td>28.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1986-01-13</td>\n",
       "      <td>28.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             head\n",
       "date             \n",
       "1985-11-14  27.61\n",
       "1985-11-28  27.73\n",
       "1985-12-14  27.91\n",
       "1985-12-28  28.13\n",
       "1986-01-13  28.32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = \"../../tests/data/\"  # relative path to data directory\n",
    "oseries1 = pd.read_csv(os.path.join(datadir, \"head_nb1.csv\"), index_col=0, parse_dates=True)\n",
    "oseries1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the timeseries to the oseries library using `pr.db.add_oseries`. Metadata can be optionally be provided as a dictionary. In this example a dictionary x and y coordinates is passed as metadata which is convenient later for automatically creating Pastas models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.db.add_oseries(oseries1, \"oseries1\", metadata={\"x\": 100300, \"y\": 400400})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The series was added to the oseries library. Let's confirm by looking at the `pr` object`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PastasProject> my_first_project: \n",
       " - <PystoreConnector object> 'my_second_connector': 1 oseries, 0 stresses, 0 models"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stresses can be added similarly using `pr.db.add_stress`. The only thing to keep in mind when adding stresses is to pass the `kind` argument so that different types of stresses (i.e. precipitation or evaporation) can be distinguished. The code below reads the precipitation and evaporation csv-files and adds them to our project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prec 2\n",
    "s = pd.read_csv(os.path.join(datadir, \"rain_nb1.csv\"), index_col=0, parse_dates=True)\n",
    "pr.db.add_stress(s, \"prec1\", kind=\"prec\", metadata={\"x\": 100300,\n",
    "                                                    \"y\": 400400})\n",
    "\n",
    "# evap 2\n",
    "s = pd.read_csv(os.path.join(datadir, \"evap_nb1.csv\"), index_col=0, parse_dates=True)\n",
    "pr.db.add_stress(s, \"evap1\", kind=\"evap\", metadata={\"x\": 100300,\n",
    "                                                    \"y\": 400400})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PastasProject> my_first_project: \n",
       " - <PystoreConnector object> 'my_second_connector': 1 oseries, 2 stresses, 0 models"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.2 Accessing timeseries and metadata](#top)<a id=\"4.2\"></a>\n",
    "\n",
    "Timeseries can be accessed through `pr.db.get_oseries()` or `pr.db.get_stresses()`. These methods accept just a name or a list of names. In the latter case a list of dataframes is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1985-11-14</td>\n",
       "      <td>27.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1985-11-28</td>\n",
       "      <td>27.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1985-12-14</td>\n",
       "      <td>27.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1985-12-28</td>\n",
       "      <td>28.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1986-01-13</td>\n",
       "      <td>28.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             head\n",
       "date             \n",
       "1985-11-14  27.61\n",
       "1985-11-28  27.73\n",
       "1985-12-14  27.91\n",
       "1985-12-28  28.13\n",
       "1986-01-13  28.32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pr.db.get_oseries(\"oseries1\")\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a list of names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prec1':               rain\n",
       " date              \n",
       " 1980-01-01  0.0033\n",
       " 1980-01-02  0.0025\n",
       " 1980-01-03  0.0003\n",
       " 1980-01-04  0.0075\n",
       " 1980-01-05  0.0080\n",
       " ...            ...\n",
       " 2016-10-27  0.0000\n",
       " 2016-10-28  0.0000\n",
       " 2016-10-29  0.0003\n",
       " 2016-10-30  0.0000\n",
       " 2016-10-31  0.0000\n",
       " \n",
       " [13454 rows x 1 columns], 'evap1':               evap\n",
       " date              \n",
       " 1980-01-01  0.0002\n",
       " 1980-01-02  0.0003\n",
       " 1980-01-03  0.0002\n",
       " 1980-01-04  0.0001\n",
       " 1980-01-05  0.0001\n",
       " ...            ...\n",
       " 2016-11-18  0.0004\n",
       " 2016-11-19  0.0003\n",
       " 2016-11-20  0.0005\n",
       " 2016-11-21  0.0003\n",
       " 2016-11-22  0.0005\n",
       " \n",
       " [13476 rows x 1 columns]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stresses = pr.db.get_stresses(['prec1', 'evap1'])\n",
    "stresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata of a timeseries can be accessed through `pr.db.get_metadata()`. Provide the library and the name to load the metadata for an oseries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>_updated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>oseries1</td>\n",
       "      <td>100300</td>\n",
       "      <td>400400</td>\n",
       "      <td>2020-01-27 13:01:01.268039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x       y                    _updated\n",
       "name                                                \n",
       "oseries1  100300  400400  2020-01-27 13:01:01.268039"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pr.db.get_metadata('oseries', \"oseries1\")\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or for multiple stresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>kind</th>\n",
       "      <th>_updated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>prec1</td>\n",
       "      <td>100300.0</td>\n",
       "      <td>400400.0</td>\n",
       "      <td>prec</td>\n",
       "      <td>2020-01-27 13:01:01.330069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>evap1</td>\n",
       "      <td>100300.0</td>\n",
       "      <td>400400.0</td>\n",
       "      <td>evap</td>\n",
       "      <td>2020-01-27 13:01:01.371037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x         y  kind                    _updated\n",
       "name                                                       \n",
       "prec1  100300.0  400400.0  prec  2020-01-27 13:01:01.330069\n",
       "evap1  100300.0  400400.0  evap  2020-01-27 13:01:01.371037"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pr.db.get_metadata('stresses', [\"prec1\", \"evap1\"])\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.3 Deleting oseries and stresses](#top)<a id=\"4.3\"></a>\n",
    "\n",
    "Deleting timeseries can be done using `pr.db.del_oseries` or `pr.db.del_stresses`. These functions accept a single name or list of names of timeseries to delete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.4 Overview of oseries and stresses](#top)<a id=\"4.4\"></a>\n",
    "\n",
    "An overview of the oseries and stresses is available through `pr.db.oseries` and `pr.db.stresses`. These are dataframes containing the metadata of all the timeseries. These dataframes are cached for performance. The cache is cleared when a timeseries is added or modified in the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>_updated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>oseries1</td>\n",
       "      <td>100300</td>\n",
       "      <td>400400</td>\n",
       "      <td>2020-01-27 13:01:01.268039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x       y                    _updated\n",
       "name                                                \n",
       "oseries1  100300  400400  2020-01-27 13:01:01.268039"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.db.oseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>kind</th>\n",
       "      <th>_updated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>prec1</td>\n",
       "      <td>100300.0</td>\n",
       "      <td>400400.0</td>\n",
       "      <td>prec</td>\n",
       "      <td>2020-01-27 13:01:01.330069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>evap1</td>\n",
       "      <td>100300.0</td>\n",
       "      <td>400400.0</td>\n",
       "      <td>evap</td>\n",
       "      <td>2020-01-27 13:01:01.371037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x         y  kind                    _updated\n",
       "name                                                       \n",
       "prec1  100300.0  400400.0  prec  2020-01-27 13:01:01.330069\n",
       "evap1  100300.0  400400.0  evap  2020-01-27 13:01:01.371037"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.db.stresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## [5. Managing Pastas models](#top)<a id=\"5\"></a>\n",
    "\n",
    "This section shows how Pastas models can be created, stored, and loaded from the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.1 Creating a model](#top)<a id=\"5.1\"></a>\n",
    "Creating a new model is straightforward using `pr.create_model()`. The `add_recharge` keyword argument allows the user to choose (default is True) whether recharge is automatically added to the model using the closest precipitation and evaporation stations in the stresses library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Cannot determine frequency of series oseries1\n",
      "INFO: Inferred frequency from time series prec1: freq=D \n",
      "INFO: Inferred frequency from time series evap1: freq=D \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(oseries=oseries1, name=oseries1, constant=True, noisemodel=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml = pr.create_model(\"oseries1\", add_recharge=True)\n",
    "ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.2 Storing a model](#top)<a id=\"5.2\"></a>\n",
    "The model that was created in the previous step is not automatically stored in the models library. Use `pr.db.add_model()` to store the model. If the model already exists, an Exception is raised warning the user the model is already in the library. Use `add_version=True` to add the model anyway.\n",
    "\n",
    "**Note:**\n",
    "The model is stored without the timeseries. It is assumed the timeseries are already stored in the oseries or stresses libraries, making it redundant to store these again in most cases. Obviously this has the potential downside that modifications to a timeseries prior to using it in a model will not be saved. In this implementation, the user is expected to add a new timeseries under a new name or version to the oseries and stresses libraries and create a new model using that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.db.add_model(ml, add_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the model again with `add_version=False` fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\n                Item already exists. To overwrite, use `overwrite=True`.\n                Otherwise, use `<collection>.append()`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-0a636dae6e72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\GitHub\\arctic_demo\\pastas_projects\\connectors.py\u001b[0m in \u001b[0;36madd_model\u001b[1;34m(self, ml, add_version)\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[0mcollection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_library\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"models\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         collection.write(ml.name, pd.DataFrame(), metadata=jsondict,\n\u001b[1;32m--> 735\u001b[1;33m                          overwrite=add_version)\n\u001b[0m\u001b[0;32m    736\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"models\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pystore\\collection.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, item, data, metadata, npartitions, chunksize, overwrite, epochdate, reload_items, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m             raise ValueError(\"\"\"\n\u001b[0;32m    114\u001b[0m                 \u001b[0mItem\u001b[0m \u001b[0malready\u001b[0m \u001b[0mexists\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mTo\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                 Otherwise, use `<collection>.append()`\"\"\")\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mItem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: \n                Item already exists. To overwrite, use `overwrite=True`.\n                Otherwise, use `<collection>.append()`"
     ]
    }
   ],
   "source": [
    "pr.db.add_model(ml, add_version=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.3 Loading a model](#top)<a id=\"5.3\"></a>\n",
    "\n",
    "Loading a stored model is simple using `pr.db.get_models()`.\n",
    "\n",
    "The model is stored as a dictionary (see `ml.to_dict()`) without the timeseries data. The timeseries in the model are picked up based on the names of those series from the respective libraries (oseries or stresses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Cannot determine frequency of series oseries1\n",
      "INFO:pastas.timeseries:Cannot determine frequency of series oseries1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(oseries=oseries1, name=oseries1, constant=True, noisemodel=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml2 = pr.db.get_models(\"oseries1\")\n",
    "ml2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.4 Overview of models](#top)<a id=\"5.4\"></a>\n",
    "\n",
    "An overview of the models is available through `pr.db.models` which lists the names of all the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oseries1'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.db.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.5 Deleting models](#top)<a id=\"5.5\"></a>\n",
    "\n",
    "Deleting the model is done with `pr.db.del_models`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.db.del_models(\"oseries1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to see if it was indeed deleted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PastasProject> my_first_project: \n",
       " - <PystoreConnector object> 'my_second_connector': 1 oseries, 2 stresses, 0 models"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.db.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## [6. Bulk operations](#top)<a id=\"5\"></a>\n",
    "\n",
    "The following bulk operations are available:\n",
    "- `create_models`: create models for all or a selection of oseries in database\n",
    "- `solve_models`: solve all or selection of models in database\n",
    "- `model_results`: get results for all or selection of models in database. Requires the `art_tools` module!\n",
    "\n",
    "Let's add some more data to the pystore to show how the bulk operations work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oseries 2\n",
    "o = pd.read_csv(os.path.join(datadir, \"obs.csv\"), index_col=0, parse_dates=True)\n",
    "o.index.name = \"oseries2\"\n",
    "pr.db.add_oseries(o, \"oseries2\", metadata={\"x\": 100000,\n",
    "                                           \"y\": 400000})\n",
    "\n",
    "# prec 2\n",
    "s = pd.read_csv(os.path.join(datadir, \"rain.csv\"), index_col=0, parse_dates=True)\n",
    "pr.db.add_stress(s, \"prec2\", kind=\"prec\", metadata={\"x\": 100000,\n",
    "                                                    \"y\": 400000})\n",
    "\n",
    "# evap 2\n",
    "s = pd.read_csv(os.path.join(datadir, \"evap.csv\"), index_col=0, parse_dates=True)\n",
    "pr.db.add_stress(s, \"evap2\", kind=\"evap\", metadata={\"x\": 100000,\n",
    "                                                    \"y\": 400000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our `PastasProject`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PastasProject> my_first_project: \n",
       " - <PystoreConnector object> 'my_second_connector': 2 oseries, 4 stresses, 0 models"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's try using the bulk methods on our database. The `pr.create_models()` method allows the user to get models for all or a selection of oseries in the database. Options include:\n",
    "- selecting specific oseries to create models for\n",
    "- automatically adding recharge based on nearest precipitation and evaporation stresses\n",
    "- solving the models\n",
    "- storing the models in the models library\n",
    "\n",
    "**Note**: when using the progressbar, for a prettier result the pastas log level should be set to ERROR using: `ps.set_log_level(\"ERROR\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first one is not working unfortunately.\n",
    "# ps.set_log_level(\"ERROR\")\n",
    "ps.logger.setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  7.27it/s]\n"
     ]
    }
   ],
   "source": [
    "mls = pr.create_models(store=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve all or a selection of models use `pr.solve_models()`. Options for this method include:\n",
    "- selecting models to solve\n",
    "- store results in models library\n",
    "- raise error (or not) when solving fails\n",
    "- print solve reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PastasProject> my_first_project: \n",
       " - <PystoreConnector object> 'my_second_connector': 2 oseries, 4 stresses, 2 models"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "pr.solve_models(store_result=True, report=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the model results (parameters, EVP and some other statistics) requires the `art_tools` module. Results can be obtained for all or a selection of models. The result is a DataFrame with the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flopy is installed in C:\\Users\\dbrak\\Anaconda3\\lib\\site-packages\\flopy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oseries2</th>\n",
       "      <th>oseries1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>recharge_A</td>\n",
       "      <td>600.68</td>\n",
       "      <td>683.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recharge_n</td>\n",
       "      <td>1.02046</td>\n",
       "      <td>1.01644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recharge_a</td>\n",
       "      <td>143.071</td>\n",
       "      <td>151.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recharge_f</td>\n",
       "      <td>-1.3681</td>\n",
       "      <td>-1.27579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>constant_d</td>\n",
       "      <td>28.0242</td>\n",
       "      <td>27.8888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noise_alpha</td>\n",
       "      <td>65.2511</td>\n",
       "      <td>49.7209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recharge_A_stderr</td>\n",
       "      <td>125.12</td>\n",
       "      <td>35.7075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recharge_n_stderr</td>\n",
       "      <td>0.0404976</td>\n",
       "      <td>0.0181703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recharge_a_stderr</td>\n",
       "      <td>30.5517</td>\n",
       "      <td>11.4023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recharge_f_stderr</td>\n",
       "      <td>0.174908</td>\n",
       "      <td>0.0608555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>constant_d_stderr</td>\n",
       "      <td>0.163869</td>\n",
       "      <td>0.0680325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noise_alpha_stderr</td>\n",
       "      <td>20.5229</td>\n",
       "      <td>5.88757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>evp</td>\n",
       "      <td>88.2639</td>\n",
       "      <td>92.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>number of observations used in calibration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>memory recharge [days]</td>\n",
       "      <td>334.501</td>\n",
       "      <td>353.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rfunc recharge</td>\n",
       "      <td>Gamma</td>\n",
       "      <td>Gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>calibration period [days]</td>\n",
       "      <td>1991</td>\n",
       "      <td>10818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             oseries2   oseries1\n",
       "recharge_A                                     600.68    683.216\n",
       "recharge_n                                    1.02046    1.01644\n",
       "recharge_a                                    143.071    151.557\n",
       "recharge_f                                    -1.3681   -1.27579\n",
       "constant_d                                    28.0242    27.8888\n",
       "noise_alpha                                   65.2511    49.7209\n",
       "recharge_A_stderr                              125.12    35.7075\n",
       "recharge_n_stderr                           0.0404976  0.0181703\n",
       "recharge_a_stderr                             30.5517    11.4023\n",
       "recharge_f_stderr                            0.174908  0.0608555\n",
       "constant_d_stderr                            0.163869  0.0680325\n",
       "noise_alpha_stderr                            20.5229    5.88757\n",
       "evp                                           88.2639    92.9142\n",
       "number of observations used in calibration        NaN        NaN\n",
       "memory recharge [days]                        334.501    353.287\n",
       "rfunc recharge                                  Gamma      Gamma\n",
       "calibration period [days]                        1991      10818"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pr.model_results()\n",
    "results.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [7. Deleting databases](#top)<a id=\"7\"></a>\n",
    "\n",
    "The `pystore_pastas.util` submodule contains functions for deleting databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting database: 'my_connector' ...\n",
      " - deleted: my_connector.oseries\n",
      " - deleted: my_connector.stresses\n",
      " - deleted: my_connector.models\n"
     ]
    }
   ],
   "source": [
    "pp.util.delete_arctic(conn.connstr, conn.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting pystore: 'my_second_connector' ... Done!\n"
     ]
    }
   ],
   "source": [
    "pp.util.delete_pystore(conn2.path, conn2.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
