{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing timeseries and Pastas models with PastasProject<a id=\"top\"></a>\n",
    "\n",
    "This notebook shows how [Pastas](https://pastas.readthedocs.io/en/latest/) timeseries and models can be managed and stored on disk. Two storage systems are currently implemented:\n",
    "- [Arctic](https://arctic.readthedocs.io/en/latest/) is a timeseries/dataframe database that sits atop [MongoDB](https://www.mongodb.com). Arctic supports pandas.DataFrames.\n",
    "- [PyStore](https://github.com/ranaroussi/pystore) is a datastore (inspired by Arctic) created for storing pandas dataframes (especially timeseries) on disk. Data is stored using fastparquet and compressed with Snappy.\n",
    "\n",
    "## Content\n",
    "1. [Getting started](#1)\n",
    "2. [The Connector objects](#2)\n",
    "   1. [ArcticConnector](#2.1)\n",
    "   2. [PystoreConnector](#2.2)\n",
    "   3. [Database structure](#2.3)\n",
    "3. [Initializing a PastasProject](#3)\n",
    "4. [Managing timeseries](#4)\n",
    "   1. [Adding oseries and stresses](#4.1)\n",
    "   2. [Accessing timeseries and metadata](#4.2)\n",
    "   3. [Deleting oseries and stresses](#4.3)\n",
    "   4. [Overview of oseries and stresses](#4.4)\n",
    "5. [Managing Pastas models](#5)\n",
    "   1. [Creating a model](#5.1)\n",
    "   2. [Storing a model](#5.2)\n",
    "   3. [Loading a model](#5.3)\n",
    "   4. [Overview of models](#5.4)\n",
    "   5. [Deleting models](#5.5)\n",
    "6. [Bulk operations](#6)\n",
    "7. [Deleting database](#7)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## [1. Getting started](#top)<a id=\"1\"></a>\n",
    "\n",
    "Use the following steps to get your PC ready for this notebook if you haven't done so already:\n",
    "\n",
    "### Getting ready for Arctic\n",
    "1. Install [Docker Desktop](https://www.docker.com/products/docker-desktop).\n",
    "2. Run `docker-compose up -d` in a terminal from the `./dockerfiles` directory.\n",
    "\n",
    "### Getting ready for Pystore\n",
    "1. Install Snappy (see the [Pystore github](https://github.com/ranaroussi/pystore#dependencies) page for for instructions). For Windows users see [this page](https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-snappy)\n",
    "2. Install Pystore using pip: `pip install pystore`.\n",
    "\n",
    "\n",
    "If no errors were encountered, you're all set. \n",
    "\n",
    "<hr>\n",
    "\n",
    "## [2. The Connector objects](#top)<a id=\"2\"></a>\n",
    "This sections shows how to initialize a connection to a new database (connecting to an existing database works the same way).\n",
    "\n",
    "Import `pastastore` and some other modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pastas as ps\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, \"../..\")\n",
    "\n",
    "import pastastore as pst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.1 ArcticConnector](#top)<a id=\"2.1\"></a>\n",
    "\n",
    "Provide information about the database. The connection string tells Arctic where the database is running (by default, if running locally the address is `mongodb://localhost:<port number>`. The project name is the user specified name for the database. \n",
    "\n",
    "If the database already exists, Arctic will connect to that existing database. In this case we're using a new database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connstr = \"mongodb://localhost:27017/\"  # for docker container with name 'mongodb' running mongodb\n",
    "name = \"my_connector\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an ArcticConnector object. In this case the object initializes a new database and provides the connection to that database.\n",
    "\n",
    "_Note: You can ignore the warnings arctic throws at you about enabling sharding._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "WARNING:arctic.store.version_store:Library created, but couldn't enable sharding: no such command: 'enablesharding'. This is OK if you're not 'admin'\nWARNING:arctic.store.version_store:Library created, but couldn't enable sharding: no such command: 'enablesharding'. This is OK if you're not 'admin'\nWARNING:arctic.store.version_store:Library created, but couldn't enable sharding: no such command: 'enablesharding'. This is OK if you're not 'admin'\n"
    }
   ],
   "source": [
    "conn = pst.ArcticConnector(name, connstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at `conn`. This shows us how many oseries, stresses and models are contained in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<ArcticConnector object> 'my_connector': 0 oseries, 0 stresses, 0 models"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the database is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.2 PystoreConnector](#top)<a id=\"2.2\"></a>\n",
    "\n",
    "The PystoreConnector requires the path to the directory containing the stores and a name for the connector. If the store already exists, pystore will link to that existing store. In this case we're creating a new store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./pystore\"\n",
    "name = \"my_second_connector\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the PystoreConnector object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn2 = pst.PystoreConnector(name, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at `conn2`. This shows us how many oseries, stresses and models are contained in the store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<PystoreConnector object> 'my_second_connector': 2 oseries, 4 stresses, 2 models"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.3 Database structure](#top)<a id=\"2.3\"></a>\n",
    "\n",
    "Regardless of the type of Connector that is used, the database/store contains 3 libraries or collections. Each of these contains specific data related to the project. The three libraries are:\n",
    "- oseries\n",
    "- stresses\n",
    "- models\n",
    "\n",
    "These libraries can be accessed through `conn.get_library()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<VersionStore at 0x276dc6c2d68>\n    <ArcticLibrary at 0x276dc3ff940, arctic_my_connector.oseries>\n        <Arctic at 0x276d68506a0, connected to MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True, maxpoolsize=4, sockettimeoutms=600000, connecttimeoutms=2000, serverselectiontimeoutms=30000)>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the ArcticConnector\n",
    "conn.get_library(\"oseries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "PyStore.collection <stresses>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the PystoreConnector\n",
    "conn2.get_library(\"stresses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library handles are not generally used directly but internally they manage the reading, writing and deleting of data from the database/store. The two handles to the libraries above are completely different objects from two different packages (`arctic` and `pystore`). To understand what they're capable of and how they work please refer to the documentation of their respective packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## [3. Initializing a PastaStore object](#top)<a id=\"3\"></a>\n",
    "\n",
    "The `PastaStore` object is used process and use the data in the database. The connector objects only manage the reading/writing/deleting of data. The `PastaStore` contains all kinds of methods to actually _do_ stuff with that data. \n",
    "\n",
    "In order to access the data the `PastaStore` object must be initialized with a Connector object. In this example, I'm using the `PystoreConnector`, but I could just as easily have used the `ArcticConnector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pst.PastaStore(\"my_first_project\", conn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<PastasProject> my_first_project: \n - <PystoreConnector object> 'my_second_connector': 2 oseries, 4 stresses, 2 models"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>kind</th>\n      <th>_updated</th>\n    </tr>\n    <tr>\n      <th>name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>prec2</td>\n      <td>100000.0</td>\n      <td>400000.0</td>\n      <td>prec</td>\n      <td>2020-03-17 12:12:52.878861</td>\n    </tr>\n    <tr>\n      <td>evap2</td>\n      <td>100000.0</td>\n      <td>400000.0</td>\n      <td>evap</td>\n      <td>2020-03-17 12:12:52.896896</td>\n    </tr>\n    <tr>\n      <td>evap1</td>\n      <td>100300.0</td>\n      <td>400400.0</td>\n      <td>evap</td>\n      <td>2020-03-17 12:12:50.761864</td>\n    </tr>\n    <tr>\n      <td>prec1</td>\n      <td>100300.0</td>\n      <td>400400.0</td>\n      <td>prec</td>\n      <td>2020-03-17 12:12:50.728865</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "              x         y  kind                    _updated\nname                                                       \nprec2  100000.0  400000.0  prec  2020-03-17 12:12:52.878861\nevap2  100000.0  400000.0  evap  2020-03-17 12:12:52.896896\nevap1  100300.0  400400.0  evap  2020-03-17 12:12:50.761864\nprec1  100300.0  400400.0  prec  2020-03-17 12:12:50.728865"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.conn.stresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important thing to remember about the `PastaStore` is that the connector is accessible through `store.conn`. So all of the methods defined in the connector objects can be accessed through e.g. `store.conn.get_library`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## [4. Managing timeseries](#top)<a id=\"4\"></a>\n",
    "\n",
    "This section explains how timeseries can be added, retrieved or deleted from the database. We'll be using the `PastaStore` object we created before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.1 Adding oseries and stresses](#top)<a id=\"4.1\"></a>\n",
    "\n",
    "Let's read some data to put into the database as an oseries. The data we are using is in the `tests/data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>head</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1985-11-14</td>\n      <td>27.61</td>\n    </tr>\n    <tr>\n      <td>1985-11-28</td>\n      <td>27.73</td>\n    </tr>\n    <tr>\n      <td>1985-12-14</td>\n      <td>27.91</td>\n    </tr>\n    <tr>\n      <td>1985-12-28</td>\n      <td>28.13</td>\n    </tr>\n    <tr>\n      <td>1986-01-13</td>\n      <td>28.32</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "             head\ndate             \n1985-11-14  27.61\n1985-11-28  27.73\n1985-12-14  27.91\n1985-12-28  28.13\n1986-01-13  28.32"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = \"../../tests/data/\"  # relative path to data directory\n",
    "oseries1 = pd.read_csv(os.path.join(datadir, \"head_nb1.csv\"), index_col=0, parse_dates=True)\n",
    "oseries1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the timeseries to the oseries library using `store.conn.add_oseries`. Metadata can be optionally be provided as a dictionary. In this example a dictionary x and y coordinates is passed as metadata which is convenient later for automatically creating Pastas models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.conn.add_oseries(oseries1, \"oseries1\", metadata={\"x\": 100300, \"y\": 400400})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The series was added to the oseries library. Let's confirm by looking at the `store` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<PastasProject> my_first_project: \n - <PystoreConnector object> 'my_second_connector': 2 oseries, 4 stresses, 2 models"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stresses can be added similarly using `store.conn.add_stress`. The only thing to keep in mind when adding stresses is to pass the `kind` argument so that different types of stresses (i.e. precipitation or evaporation) can be distinguished. The code below reads the precipitation and evaporation csv-files and adds them to our project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prec 2\n",
    "s = pd.read_csv(os.path.join(datadir, \"rain_nb1.csv\"), index_col=0, parse_dates=True)\n",
    "store.conn.add_stress(s, \"prec1\", kind=\"prec\", metadata={\"x\": 100300,\n",
    "                                                    \"y\": 400400})\n",
    "\n",
    "# evap 2\n",
    "s = pd.read_csv(os.path.join(datadir, \"evap_nb1.csv\"), index_col=0, parse_dates=True)\n",
    "store.conn.add_stress(s, \"evap1\", kind=\"evap\", metadata={\"x\": 100300,\n",
    "                                                    \"y\": 400400})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<PastasProject> my_first_project: \n - <PystoreConnector object> 'my_second_connector': 2 oseries, 4 stresses, 2 models"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.2 Accessing timeseries and metadata](#top)<a id=\"4.2\"></a>\n",
    "\n",
    "Timeseries can be accessed through `store.conn.get_oseries()` or `store.conn.get_stresses()`. These methods accept just a name or a list of names. In the latter case a list of dataframes is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>head</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1985-11-14</td>\n      <td>27.61</td>\n    </tr>\n    <tr>\n      <td>1985-11-28</td>\n      <td>27.73</td>\n    </tr>\n    <tr>\n      <td>1985-12-14</td>\n      <td>27.91</td>\n    </tr>\n    <tr>\n      <td>1985-12-28</td>\n      <td>28.13</td>\n    </tr>\n    <tr>\n      <td>1986-01-13</td>\n      <td>28.32</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "             head\ndate             \n1985-11-14  27.61\n1985-11-28  27.73\n1985-12-14  27.91\n1985-12-28  28.13\n1986-01-13  28.32"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = store.conn.get_oseries(\"oseries1\")\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a list of names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'prec1':               rain\n date              \n 1980-01-01  0.0033\n 1980-01-02  0.0025\n 1980-01-03  0.0003\n 1980-01-04  0.0075\n 1980-01-05  0.0080\n ...            ...\n 2016-10-27  0.0000\n 2016-10-28  0.0000\n 2016-10-29  0.0003\n 2016-10-30  0.0000\n 2016-10-31  0.0000\n \n [13454 rows x 1 columns], 'evap1':               evap\n date              \n 1980-01-01  0.0002\n 1980-01-02  0.0003\n 1980-01-03  0.0002\n 1980-01-04  0.0001\n 1980-01-05  0.0001\n ...            ...\n 2016-11-18  0.0004\n 2016-11-19  0.0003\n 2016-11-20  0.0005\n 2016-11-21  0.0003\n 2016-11-22  0.0005\n \n [13476 rows x 1 columns]}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stresses = store.conn.get_stresses(['prec1', 'evap1'])\n",
    "stresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata of a timeseries can be accessed through `store.conn.get_metadata()`. Provide the library and the name to load the metadata for an oseries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>_updated</th>\n    </tr>\n    <tr>\n      <th>name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>oseries1</td>\n      <td>100300</td>\n      <td>400400</td>\n      <td>2020-03-17 13:01:52.854806</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "               x       y                    _updated\nname                                                \noseries1  100300  400400  2020-03-17 13:01:52.854806"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = store.conn.get_metadata('oseries', \"oseries1\")\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or for multiple stresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>kind</th>\n      <th>_updated</th>\n    </tr>\n    <tr>\n      <th>name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>prec1</td>\n      <td>100300.0</td>\n      <td>400400.0</td>\n      <td>prec</td>\n      <td>2020-03-17 13:01:52.918807</td>\n    </tr>\n    <tr>\n      <td>evap1</td>\n      <td>100300.0</td>\n      <td>400400.0</td>\n      <td>evap</td>\n      <td>2020-03-17 13:01:52.958770</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "              x         y  kind                    _updated\nname                                                       \nprec1  100300.0  400400.0  prec  2020-03-17 13:01:52.918807\nevap1  100300.0  400400.0  evap  2020-03-17 13:01:52.958770"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = store.conn.get_metadata('stresses', [\"prec1\", \"evap1\"])\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.3 Deleting oseries and stresses](#top)<a id=\"4.3\"></a>\n",
    "\n",
    "Deleting timeseries can be done using `store.conn.del_oseries` or `store.conn.del_stresses`. These functions accept a single name or list of names of timeseries to delete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.4 Overview of oseries and stresses](#top)<a id=\"4.4\"></a>\n",
    "\n",
    "An overview of the oseries and stresses is available through `store.conn.oseries` and `store.conn.stresses`. These are dataframes containing the metadata of all the timeseries. These dataframes are cached for performance. The cache is cleared when a timeseries is added or modified in the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>_updated</th>\n    </tr>\n    <tr>\n      <th>name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>oseries2</td>\n      <td>100000.0</td>\n      <td>400000.0</td>\n      <td>2020-03-17 12:12:52.860898</td>\n    </tr>\n    <tr>\n      <td>oseries1</td>\n      <td>100300.0</td>\n      <td>400400.0</td>\n      <td>2020-03-17 13:01:52.854806</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                 x         y                    _updated\nname                                                    \noseries2  100000.0  400000.0  2020-03-17 12:12:52.860898\noseries1  100300.0  400400.0  2020-03-17 13:01:52.854806"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.conn.oseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>kind</th>\n      <th>_updated</th>\n    </tr>\n    <tr>\n      <th>name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>prec2</td>\n      <td>100000.0</td>\n      <td>400000.0</td>\n      <td>prec</td>\n      <td>2020-03-17 12:12:52.878861</td>\n    </tr>\n    <tr>\n      <td>evap2</td>\n      <td>100000.0</td>\n      <td>400000.0</td>\n      <td>evap</td>\n      <td>2020-03-17 12:12:52.896896</td>\n    </tr>\n    <tr>\n      <td>evap1</td>\n      <td>100300.0</td>\n      <td>400400.0</td>\n      <td>evap</td>\n      <td>2020-03-17 13:01:52.958770</td>\n    </tr>\n    <tr>\n      <td>prec1</td>\n      <td>100300.0</td>\n      <td>400400.0</td>\n      <td>prec</td>\n      <td>2020-03-17 13:01:52.918807</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "              x         y  kind                    _updated\nname                                                       \nprec2  100000.0  400000.0  prec  2020-03-17 12:12:52.878861\nevap2  100000.0  400000.0  evap  2020-03-17 12:12:52.896896\nevap1  100300.0  400400.0  evap  2020-03-17 13:01:52.958770\nprec1  100300.0  400400.0  prec  2020-03-17 13:01:52.918807"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.conn.stresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## [5. Managing Pastas models](#top)<a id=\"5\"></a>\n",
    "\n",
    "This section shows how Pastas models can be created, stored, and loaded from the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.1 Creating a model](#top)<a id=\"5.1\"></a>\n",
    "Creating a new model is straightforward using `pr.create_model()`. The `add_recharge` keyword argument allows the user to choose (default is True) whether recharge is automatically added to the model using the closest precipitation and evaporation stations in the stresses library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "INFO: Cannot determine frequency of series oseries1\nINFO:pastas.timeseries:Cannot determine frequency of series oseries1\nINFO: Inferred frequency from time series prec1: freq=D \nINFO:pastas.timeseries:Inferred frequency from time series prec1: freq=D \nINFO: Inferred frequency from time series evap1: freq=D \nINFO:pastas.timeseries:Inferred frequency from time series evap1: freq=D \n"
    },
    {
     "data": {
      "text/plain": "Model(oseries=oseries1, name=oseries1, constant=True, noisemodel=True)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml = store.create_model(\"oseries1\", add_recharge=True)\n",
    "ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.2 Storing a model](#top)<a id=\"5.2\"></a>\n",
    "The model that was created in the previous step is not automatically stored in the models library. Use `store.conn.add_model()` to store the model. If the model already exists, an Exception is raised warning the user the model is already in the library. Use `add_version=True` to add the model anyway.\n",
    "\n",
    "**Note:**\n",
    "The model is stored without the timeseries. It is assumed the timeseries are already stored in the oseries or stresses libraries, making it redundant to store these again in most cases. Obviously this has the potential downside that modifications to a timeseries prior to using it in a model will not be saved. In this implementation, the user is expected to add a new timeseries under a new name or version to the oseries and stresses libraries and create a new model using that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.conn.add_model(ml, add_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.3 Loading a model](#top)<a id=\"5.3\"></a>\n",
    "\n",
    "Loading a stored model is simple using `store.conn.get_models()`.\n",
    "\n",
    "The model is stored as a dictionary (see `ml.to_dict()`) without the timeseries data. The timeseries in the model are picked up based on the names of those series from the respective libraries (oseries or stresses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "INFO: Cannot determine frequency of series oseries1\nINFO:pastas.timeseries:Cannot determine frequency of series oseries1\n"
    },
    {
     "data": {
      "text/plain": "Model(oseries=oseries1, name=oseries1, constant=True, noisemodel=True)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml2 = store.conn.get_models(\"oseries1\")\n",
    "ml2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.4 Overview of models](#top)<a id=\"5.4\"></a>\n",
    "\n",
    "An overview of the models is available through `store.conn.models` which lists the names of all the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'oseries1', 'oseries2'}"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.conn.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.5 Deleting models](#top)<a id=\"5.5\"></a>\n",
    "\n",
    "Deleting the model is done with `store.conn.del_models`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.conn.del_models(\"oseries1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to see if it was indeed deleted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<PastasProject> my_first_project: \n - <PystoreConnector object> 'my_second_connector': 2 oseries, 4 stresses, 1 models"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'oseries2'}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.conn.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## [6. Bulk operations](#top)<a id=\"5\"></a>\n",
    "\n",
    "The following bulk operations are available:\n",
    "- `create_models`: create models for all or a selection of oseries in database\n",
    "- `solve_models`: solve all or selection of models in database\n",
    "- `model_results`: get results for all or selection of models in database. Requires the `art_tools` module!\n",
    "\n",
    "Let's add some more data to the pystore to show how the bulk operations work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oseries 2\n",
    "o = pd.read_csv(os.path.join(datadir, \"obs.csv\"), index_col=0, parse_dates=True)\n",
    "o.index.name = \"oseries2\"\n",
    "store.conn.add_oseries(o, \"oseries2\", metadata={\"x\": 100000,\n",
    "                                           \"y\": 400000})\n",
    "\n",
    "# prec 2\n",
    "s = pd.read_csv(os.path.join(datadir, \"rain.csv\"), index_col=0, parse_dates=True)\n",
    "store.conn.add_stress(s, \"prec2\", kind=\"prec\", metadata={\"x\": 100000,\n",
    "                                                    \"y\": 400000})\n",
    "\n",
    "# evap 2\n",
    "s = pd.read_csv(os.path.join(datadir, \"evap.csv\"), index_col=0, parse_dates=True)\n",
    "store.conn.add_stress(s, \"evap2\", kind=\"evap\", metadata={\"x\": 100000,\n",
    "                                                    \"y\": 400000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our `PastaStore`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<PastasProject> my_first_project: \n - <PystoreConnector object> 'my_second_connector': 2 oseries, 4 stresses, 1 models"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's try using the bulk methods on our database. The `pr.create_models()` method allows the user to get models for all or a selection of oseries in the database. Options include:\n",
    "- selecting specific oseries to create models for\n",
    "- automatically adding recharge based on nearest precipitation and evaporation stresses\n",
    "- solving the models\n",
    "- storing the models in the models library\n",
    "\n",
    "**Note**: when using the progressbar, for a prettier result the pastas log level should be set to ERROR using: `ps.set_log_level(\"ERROR\")` or `ps.logger.setLevel(\"ERROR\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to suppress most of the log messages\n",
    "ps.logger.setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 2/2 [00:00<00:00,  6.77it/s]\n"
    }
   ],
   "source": [
    "mls = store.create_models(store=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve all or a selection of models use `pr.solve_models()`. Options for this method include:\n",
    "- selecting models to solve\n",
    "- store results in models library\n",
    "- raise error (or not) when solving fails\n",
    "- print solve reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<PastasProject> my_first_project: \n - <PystoreConnector object> 'my_second_connector': 2 oseries, 4 stresses, 2 models"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 2/2 [00:01<00:00,  1.53it/s]\n"
    }
   ],
   "source": [
    "store.solve_models(store_result=True, report=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the model results (parameters, EVP and some other statistics) requires the `art_tools` module. Results can be obtained for all or a selection of models. The result is a DataFrame with the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "flopy is installed in c:\\github\\flopy\\flopy\n100%|██████████| 2/2 [00:00<00:00,  4.72it/s]\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>oseries2</th>\n      <th>oseries1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>recharge_A</td>\n      <td>600.68</td>\n      <td>683.214</td>\n    </tr>\n    <tr>\n      <td>recharge_n</td>\n      <td>1.02046</td>\n      <td>1.01644</td>\n    </tr>\n    <tr>\n      <td>recharge_a</td>\n      <td>143.071</td>\n      <td>151.557</td>\n    </tr>\n    <tr>\n      <td>recharge_f</td>\n      <td>-1.3681</td>\n      <td>-1.27579</td>\n    </tr>\n    <tr>\n      <td>constant_d</td>\n      <td>28.0242</td>\n      <td>27.8888</td>\n    </tr>\n    <tr>\n      <td>noise_alpha</td>\n      <td>65.2511</td>\n      <td>49.721</td>\n    </tr>\n    <tr>\n      <td>recharge_A_stderr</td>\n      <td>125.12</td>\n      <td>35.7075</td>\n    </tr>\n    <tr>\n      <td>recharge_n_stderr</td>\n      <td>0.0404976</td>\n      <td>0.0181703</td>\n    </tr>\n    <tr>\n      <td>recharge_a_stderr</td>\n      <td>30.5517</td>\n      <td>11.4023</td>\n    </tr>\n    <tr>\n      <td>recharge_f_stderr</td>\n      <td>0.174908</td>\n      <td>0.0608557</td>\n    </tr>\n    <tr>\n      <td>constant_d_stderr</td>\n      <td>0.163869</td>\n      <td>0.0680324</td>\n    </tr>\n    <tr>\n      <td>noise_alpha_stderr</td>\n      <td>20.5229</td>\n      <td>5.88759</td>\n    </tr>\n    <tr>\n      <td>evp</td>\n      <td>88.2639</td>\n      <td>92.9143</td>\n    </tr>\n    <tr>\n      <td>number of observations used in calibration</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>memory recharge [days]</td>\n      <td>334.501</td>\n      <td>353.287</td>\n    </tr>\n    <tr>\n      <td>rfunc recharge</td>\n      <td>Gamma</td>\n      <td>Gamma</td>\n    </tr>\n    <tr>\n      <td>calibration period [days]</td>\n      <td>1991</td>\n      <td>10818</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                             oseries2   oseries1\nrecharge_A                                     600.68    683.214\nrecharge_n                                    1.02046    1.01644\nrecharge_a                                    143.071    151.557\nrecharge_f                                    -1.3681   -1.27579\nconstant_d                                    28.0242    27.8888\nnoise_alpha                                   65.2511     49.721\nrecharge_A_stderr                              125.12    35.7075\nrecharge_n_stderr                           0.0404976  0.0181703\nrecharge_a_stderr                             30.5517    11.4023\nrecharge_f_stderr                            0.174908  0.0608557\nconstant_d_stderr                            0.163869  0.0680324\nnoise_alpha_stderr                            20.5229    5.88759\nevp                                           88.2639    92.9143\nnumber of observations used in calibration        NaN        NaN\nmemory recharge [days]                        334.501    353.287\nrfunc recharge                                  Gamma      Gamma\ncalibration period [days]                        1991      10818"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = store.model_results()\n",
    "results.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [7. Deleting databases](#top)<a id=\"7\"></a>\n",
    "\n",
    "The `pystore_pastas.util` submodule contains functions for deleting databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Deleting database: 'my_connector' ...\n - deleted: my_connector.oseries\n - deleted: my_connector.stresses\n - deleted: my_connector.models\n"
    }
   ],
   "source": [
    "pst.util.delete_arctic(conn.connstr, conn.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Deleting pystore: 'my_second_connector' ... Done!\n"
    }
   ],
   "source": [
    "pst.util.delete_pystore(conn2.path, conn2.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}